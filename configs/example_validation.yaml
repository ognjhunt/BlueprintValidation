schema_version: v1
project_name: "Blueprint Validation Pilot"

# ---- Facilities ----
facilities:
  facility_a:
    name: "Warehouse A - Durham"
    ply_path: ./data/facilities/facility_a/splat.ply
    description: "Large warehouse with shelving racks, loading dock, concrete floors"
    landmarks:
      - "loading dock on east wall"
      - "shelving racks in center"
      - "break room in northwest corner"
    floor_height_m: 0.0
    ceiling_height_m: 6.0
    manipulation_zones:
      - name: shelf_tote_pick
        approach_point: [2.1, 0.5, 0.8]
        target_point: [2.1, 1.5, 0.3]
        camera_height_m: 0.6
        camera_look_down_deg: 45
        arc_radius_m: 0.4
      - name: packing_station_place
        approach_point: [5.0, 0.0, 0.9]
        target_point: [5.0, 0.5, 0.9]

  facility_b:
    name: "Warehouse B - Raleigh"
    ply_path: ./data/facilities/facility_b/splat.ply
    description: "Smaller warehouse with conveyor system, narrow aisles"
    landmarks:
      - "conveyor belt along south wall"
      - "narrow aisles between racks"
      - "office area on second floor"
    floor_height_m: 0.0
    ceiling_height_m: 5.0
    manipulation_zones:
      - name: conveyor_place
        approach_point: [4.0, 0.0, 0.9]
        target_point: [4.0, 0.5, 0.9]

# ---- Stage 1: Render ----
render:
  resolution: [480, 640]
  fps: 10
  num_frames: 49
  camera_height_m: 1.2
  camera_look_down_deg: 15
  camera_paths:
    - type: orbit
      radius_m: 3.0
      num_orbits: 2
    - type: sweep
      length_m: 10.0
    # Close-range arc around a tote/bin manipulation zone (gripper-centric view).
    - type: file
      path: ./camera_paths/manipulation_closeup_arc.json
    # Auto-generated gripper-height arc for each manipulation zone.
    - type: manipulation
      height_override_m: 0.6
      look_down_override_deg: 45
  num_clips_per_path: 3

# ---- Stage 1b: Robot arm compositing (URDF + camera extrinsics) ----
robot_composite:
  enabled: false
  urdf_path: ./robots/sample_6dof_arm.urdf
  end_effector_link: wrist_3_link
  base_xyz: [0.0, 0.0, 0.0]
  base_rpy: [0.0, 0.0, 0.0]
  # Example start/end joint positions (radians) for pick-to-place style sweep
  start_joint_positions: [0.0, -1.1, 1.2, -1.0, -1.2, 0.0]
  end_joint_positions: [0.4, -0.8, 1.0, -1.2, -1.0, 0.3]
  min_visible_joint_ratio: 0.6
  min_consistency_score: 0.6
  line_color_bgr: [50, 180, 255]
  line_thickness: 3

# ---- Stage 1c: Optional Gemini image polish ----
gemini_polish:
  enabled: false
  model: gemini-3.1-flash-image-preview
  api_key_env: GOOGLE_GENAI_API_KEY
  prompt: "Preserve robot arm pose and scene geometry exactly. Improve photorealism and blending quality."
  sample_every_n_frames: 2

# ---- Stage 2: Enrich ----
enrich:
  cosmos_model: nvidia/Cosmos-Transfer2.5-2B
  cosmos_checkpoint: ./data/checkpoints/cosmos-transfer-2.5-2b/
  cosmos_repo: /opt/cosmos-transfer
  controlnet_inputs: [rgb, depth]
  num_variants_per_render: 5
  guidance: 7.0
  variants:
    - name: daylight_empty
      prompt: "Bright daylight, empty clean industrial space, polished concrete floors"
    - name: daylight_busy
      prompt: "Bright daylight, workers in safety vests, forklifts moving"
    - name: evening_dim
      prompt: "Dim evening lighting, overhead fluorescents casting shadows"
    - name: wet_floor
      prompt: "Wet reflective concrete floor, caution signs, overhead lighting"
    - name: cluttered
      prompt: "Boxes and pallets scattered, busy workspace, equipment visible"

# ---- Stage 3: Fine-tune ----
finetune:
  dreamdojo_repo: /opt/DreamDojo
  dreamdojo_checkpoint: ./data/checkpoints/DreamDojo/2B_pretrain/
  # Optional DreamDojo config script path or config name (without .sh) under dreamdojo_repo/configs.
  # experiment_config: post-training/2b_720p_adapted_17f
  model_size: 2B
  # LoRA via Cosmos config system (model.config.train_architecture=lora)
  use_lora: true
  lora_rank: 32
  lora_alpha: 32
  lora_target_modules: "q_proj,k_proj,v_proj,output_proj,mlp.layer1,mlp.layer2"
  learning_rate: 1.0e-4
  num_epochs: 50
  batch_size: 1
  gradient_accumulation_steps: 4
  warmup_steps: 100
  save_every_n_epochs: 10
  max_training_hours: 72

# ---- Stage 4: Policy Eval ----
eval_policy:
  openvla_model: openvla/openvla-7b
  openvla_checkpoint: ./data/checkpoints/openvla-7b/
  unnorm_key: bridge_orig
  num_rollouts: 50
  max_steps_per_rollout: 100
  conditions: ["baseline", "adapted"]  # "trained" added automatically when S3b succeeds
  tasks:
    - "Navigate forward through the corridor"
    - "Turn left at the intersection"
    - "Approach the nearest obstacle"
  manipulation_tasks:
    - "Approach the tote on the floor pallet"
    - "Align gripper with tote handles"
    - "Lift the tote to shelf level one"
    - "Place the tote onto the target shelf"
    - "Pick from left bin and place into right bin"
    - "Regrasp the tote and stabilize before placement"
  vlm_judge:
    model: gemini-3-flash-preview
    api_key_env: GOOGLE_GENAI_API_KEY
    enable_agentic_vision: true

# ---- Stage 3b: Optional OpenVLA policy fine-tune ----
# Uses official OpenVLA finetune entrypoint (torchrun vla-scripts/finetune.py).
# Keep disabled unless you have an OpenVLA-compatible dataset root.
policy_finetune:
  enabled: false
  openvla_repo: /opt/openvla
  finetune_script: vla-scripts/finetune.py
  # data_root_dir should contain datasets like <data_root_dir>/bridge_orig
  data_root_dir: ./data/openvla_datasets
  dataset_name: bridge_orig
  lora_rank: 32
  batch_size: 8
  grad_accumulation_steps: 2
  learning_rate: 5.0e-4
  save_steps: 1000
  max_steps: 5000
  image_aug: true
  nproc_per_node: 1

# ---- Policy adapter (multi-policy interface) ----
policy_adapter:
  name: openvla

# ---- Stage 4b: Rollout -> RLDS-style dataset export ----
rollout_dataset:
  enabled: true
  seed: 17
  train_split: 0.8
  min_steps_per_rollout: 4
  task_score_threshold: 7.0
  include_failed_rollouts: false
  max_action_delta_norm: 5.0
  require_consistent_action_dim: true
  baseline_dataset_name: blueprint_baseline_generated
  adapted_dataset_name: blueprint_site_generated
  export_dir: ./data/outputs/policy_datasets

# ---- Stage 4d: Trained policy A/B comparison ----
policy_compare:
  enabled: true
  heldout_num_rollouts: 20
  heldout_seed: 123
  eval_world_model: adapted
  task_score_success_threshold: 7.0
  manipulation_task_keywords: [pick, grasp, lift, place, stack, regrasp, tote, bin]
  require_grasp_for_manipulation: true
  require_lift_for_manipulation: true
  require_place_for_manipulation: true

# ---- Stage 5: Visual Fidelity ----
eval_visual:
  metrics: [psnr, ssim, lpips]
  lpips_backbone: alex

# ---- Stage 6: Spatial Accuracy ----
eval_spatial:
  num_sample_frames: 20
  vlm_model: gemini-3-flash-preview

# ---- Stage 7: Cross-Site ----
eval_crosssite:
  num_clips_per_model: 30
  vlm_model: gemini-3-flash-preview

# ---- Hardware / Cloud ----
cloud:
  provider: runpod
  gpu_type: H100
  num_gpus: 1
  max_cost_usd: 500
  auto_shutdown: true
